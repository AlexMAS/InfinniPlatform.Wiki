---
layout: default
title: Cassandra: общие концепции
position: 1
categories: 
tags: 
---

Производится обзорная характеристика возможностей [Cassandra](http://cassandra.apache.org/).

# Общие принципы

Есть несколько базовых элементов, которые следует рассмотреть в самом начале:

* Keyspace - пространство ключей (аналог базы данных в RDBMS)
* ColumnFamily - семейство колонок (аналог таблицы в RDBMS)
* Column - колонка (аналог колонки таблицы в RDBMS)
* Row - строка (аналог строки таблицы в RDBMS)

Связь между этими элементами следующая:

* Keyspace состоит из множества ColumnFamily
* ColumnFamily состоит из множества Row
* Row состоит из множества Column

Колонки бывают трех типов:

* Column - "обычные колонка" представляет собой пару "ключ - значение", где "ключ" - наименование обычной колонки, "значение" - значение колонки
* Super Column [obsolete] - "супер-колонка" представляет собой пару "ключ - набор обычных колонок", где "ключ" - наименование супер-колонки, "набор обычных колонок" - список "обычных колонок" (см. выше)
* Composite Type Column - "композитная колонка" представляет собой пару "композитный ключ - значение", где "композитный ключ" - некоторый кортеж, уникально идентифицирующий колонку, "значение" - значение колонки

Composite Type Column является альтернативой Super Column, которая работает значительно быстрей (до 3 раз - по некоторым неофициальным источникам) и предоставляет значительно больше гибкости при разработке модели данных.

По аналогии, семейства колонок бывают трех типов:

* ColumnFamily - "обычное семейство колонок" представляет собой набор строк, которые могут содержать **только** "обычные колонки"
* SuperColumnFamily [obsolete] - "семейство супер-колонок" представляет собой набор строк, которые могут содержать **только** "супер-колонки"
* CompositeTypeColumnFamily - "семейство композитных колонок" представляет собой набор строк, которые могут содержать **только** "композитные колонки"

Наконец, можно перечислить несколько основополагающих концепций:

* Полное отсутствие такого понятия, как "схема данных", то есть каждая строчка одного семейства колонок может содержать разный набор колонок
* В рамках одного семейства колонок может быть произвольное количество строк, в рамках одной строки - произвольное количество колонок
* Все данные, а также наименование семейства колонок, колонок, строк представлены в бинарном виде, то есть каждый элемент хранится в виде массива байт
* Из-за бинарного представления всех данных, в качестве наименования строк и колонок можно использовать все, что угодно - любой тип данных (числа, строки, даты и т.п.)

Ниже приведена JSON-подобная структура, которая показывает соотношение между описанными выше элементами.

```
Keyspace:
   {
      ColumnFamily:
         [
            Row: { Column: Value, Column: Value, ... },
            Row: { Column: Value, Column: Value, ... },
            ...
         ],
      SuperColumnFamily:
         [
            Row: { SuperColumn: { Column: Value, Column: Value, ... }, ... },
            Row: { SuperColumn: { Column: Value, Column: Value, ... }, ... },
            ...
         ],
      CompositeTypeColumnFamily:
         [
            Row: { (Column, Column, ...): Value, (Column, Column, ...): Value, ... },
            Row: { (Column, Column, ...): Value, (Column, Column, ...): Value, ... },
            ...
         ],
      ...
   }
```

Обращаю внимание, что приведенное JSON-подобное описание приведено только для удобства восприятия информации, данные в Cassandra хранятся в бинарном формате.

Также следует обозначить следующие важные моменты:

* Децентрализованное хранение данных - возможность горизонтального масштабирования путем **простого** добавления новых узлов в кластер
* Повышенная отказоустойчивость - каждая запись дублируется на нескольких узлах кластера
* Высокая скорость чтения и записи (при этом скорость записи в несколько раз выше)
* Высокая пропускная способность - пропускная способность чтения и записи увеличиваются **линейно** с добавлением новых узлов
* Гибкая модель данных - отсутствие жесткой схемы данных
* Безразмерное хранилище - нет ограничений на объем
* Доступ к записям по ключу - сложность выборки всегда O(1)

Учитывая эти моменты есть некоторые особенности в работе, например:

* Данные сортируются, как только вы запишете их в кластер и **всегда** остаются отсортированными (для повышения производительности при чтении).
* Столбцы внутри строк **всегда** отсортированы по имени столбца (как именно будут сравниваться имена при сортировки зависит от настроек семейства колонок, указанных при ее создании)

 

Все эти моменты следует учитывать при проектировании системы, чтобы принятая модель данных наилучшим образом соответствовала сценариям доступа к данным.

# Распределение данных

Cassandra позволяет задавать стратегию распределения данных:

* Random partitioner - "случайный разметчик" распределяет данные в зависимости от md5 значения ключа. Даёт больше преимуществ, так как не нужно заботиться о равномерном распределение данных между серверами и подобных проблемах.
* Byte-ordered partitioner - "порядковый разметчик" учитывает само битовое представление ключа. Используют в редких случаях, например если необходимы интервальные запросы (range scan).

Важно заметить, что выбор стратегии производится **перед созданием кластера** и фактически не может быть изменён без полной перезагрузки данных.

Для распределения данных Cassandra использует технику, известную как **согласованное хеширование** (consistent hashing). Этот подход позволяет распределить данные между узлами и сделать так, что при добавлении и удалении нового узла количество пересылаемых данных было небольшим. Для этого каждому узлу ставится в соответствие метка (token), которая разбивает на части множество всех md5 значений ключей. Так как в большинстве случаев используется "случайный разметчик", рассмотрим его. Для определения в каких узлах будут храниться данные, просто перебираются все метки узлов от меньшего к большему, и, когда значение метки становится больше, чем значение md5 ключа, то этот узел вместе с некоторым количеством последующих узлов (в порядке меток) выбирается для сохранения. Общее число выбранных узлов должно быть равным **уровню репликации** (replication factor). Уровень репликации задаётся для каждого пространства ключей и позволяет регулировать избыточность данных (data redundancy). Перед тем, как добавить узел в кластер, необходимо задать ему метку. От того, какой процент ключей покрывает промежуток между этой меткой и следующей, зависит сколько данных будет храниться на узле. Весь набор меток для кластера называется кольцом (ring).

# Согласованность данных

 

Узлы кластера Cassandra **равноценны**, и клиенты могут соединятся с **любым** из них, как для записи, так и для чтения. Запросы проходят стадию координации, во время которой, выяснив при помощи ключа и разметчика на каких узлах должны располагаться данные, сервер посылает запросы к этим узлам. Будем называть узел, который выполняет координацию — **координатором** (coordinator), а узлы, которые выбраны для сохранения записи с данным ключом — **узлами-реплик** (replica nodes). Физически координатором может быть один из узлов-реплик — это зависит только от ключа, разметчика и меток. Для каждого запроса, как на чтение, так и на запись, есть возможность задать **уровень согласованности данных**. Для записи этот уровень будет влиять на количество узлов-реплик, с которых будет ожидаться подтверждение удачного окончания операции (данные записались) перед тем, как вернуть пользователю управление. Для чтения уровень согласованности будет влиять на количество узлов-реплик, с которых будет производиться чтение. Таким образом, можно регулировать временные задержки операций чтения, записи и настраивать согласованность, а также доступность (availability) каждой из видов операций.

# Восстановление данных

Cassandra поддерживает три механизма восстановления данных:

* Чтение с восстановлением (read repair). Во время чтения данные запрашиваются со всех реплик и сравниваются уже после завершения координации. Та колонка, которая имеет последнюю метку времени, распространится на узлы, где метки устаревшие.
* Ненаправленной отправки (hinted handoff). Позволяет сохранить информацию об операции записи на координаторе в том случае, если запись на какой-либо из узлов не удалась. Позже, когда это будет возможно, запись повторится.
* Анти-энтропийное восстановление узла (anti-entropy node repair). Процесс восстановления всех реплик, который должен запускаться регулярно вручную при помощи команды "nodetool repair" и позволяет поддержать количество реплик всех данных, которые возможно были не восстановлены первыми двумя способами, на требуемом уровне репликации.

# Запись данных

 Когда данные приходят после координации на узел непосредственно для записи, то они попадают в две структуры данных: в **таблицу в памяти** (memtable) и в **журнал закрепления** (commit log). Таблица в памяти существует для каждого семейства колонок и позволяет запомнить значение моментально. Технически это hash-таблица (hashmap) с возможностью одновременного доступа (concurrent access) на основе структуры данных, называемой "списками с пропусками" (skip list). Журнал закрепления один на всё пространство ключей и сохраняется на диске. Журнал представляет собой последовательность операций модификации. Так же он разбивается на части при достижении определённого размера.

Для определения момента сохранения существует ограничение объёма занимаемыми таблицами в памяти (memtable_total_spacein_mb), по умолчанию это ⅓ максимального размера кучи Java (Java heapspace). При заполнении таблицами в памяти объёма больше чем это ограничение, Cassandra создает новую таблицу и записывает старую таблицу в памяти на диск в виде **сохраненной таблицы** (SSTable). Сохраненная таблица после создания больше никогда не модифицируется (is immutable). Когда происходит сохранение на диск, то части журнала закрепления помечаются как свободные, таким образом освобождая занятое журналом место на диске.

 Такая организация позволяет сделать скорость записи ограниченной скоростью последовательной записи на жесткий диск и при этом гарантировать долговечность данных (data durability). Журнал закрепления в случае аварийного останова узла читается при старте сервиса Cassandra и восстанавливает все таблицы в памяти. Получается, что скорость упирается во время последовательной записи на диск, а у современных жёстких дисков это порядка 100 Mb/sec. По этой причине журнал закрепления советуют вынести на отдельный дисковый носитель.

# Уплотнение данных

Рано или поздно возникнет ситуация, когда в более старой сохраненной таблице и более новой будут содержаться старые и новые данные. Для того, чтобы гарантировать целостность, Cassandra обязана читать все эти сохраненные таблицы и выбирать данные с последней меткой времени. Получается, что количество операций позиционирования жесткого диска при чтении пропорционально количеству сохраненных таблиц. Поэтому для того, чтобы освободить перезаписанные данные и уменьшить количество сохраненных таблиц, существует **процесс уплотнения** (compaction). Он читает последовательно несколько сохраненных таблиц и записывает новую сохраненную таблицу, в которой объединены данные по меткам времени. Когда таблица полностью записана и введена в использование, Cassandra может освободить таблицы-источники (таблицами, которые ее образовали). Таким образом, если таблицы содержали перезаписанные данные, то эта избыточность устраняется. Понятно, что во время такой операции объем избыточности увеличивается - новая сохраненная таблица существует на диске вместе с таблицами-источниками, а это значит, что объем места на диске всегда должен быть такой, чтобы можно было произвести уплотнение.

# Удаление данных

С точки зрения внутреннего устройства, операции удаление колонок - это операции записи специального значения - **затирающего значения** (tombstone). Когда такое значение получается в результате чтения, то оно пропускается, словно такого значения никогда и не существовало. В результате же уплотнения, такие значения постепенно вытесняют устаревшие реальные значения и, возможно, исчезают вовсе. Если же появятся колонки с реальными данными с еще более новыми метками времени, то они перетрут, в конце концов, и эти затирающие значения.

# Транзакционность

Кассандра поддерживает транзакционность на уровне **одной записи** (Row), то есть для набора колонок с одним ключом.

# Язык запросов

* **Thrift API** - низкоуровневый бинарный язык запросов
* **CQL** (Cassandra Query Language) - высокоуровневый SQL-подобный язык запросов к Cassandra

На момент написания данной заметки была актуальна Cassandra 1.2 и CQL 3. В целом на этот момент официальные и не очень ресурсы сходятся в едином мнении - в новых разработках рекомендуется использовать CQL, а не Thrift."CQL2 был представлен в Cassandra v0.8 и расширен в v1.0. Целью было предоставить SQL-подобный язык для Cassandra, который будет более расширяем, чем Thrift API. Однако CQL2 был очень близок к концепции Thrift. [...] Таким образом, мы вернулись к своим чертежам в Cassandra 1.1 и пересмотрели язык CQL, чтобы решить указанные проблемы." ([CQL3 for Cassandra experts](http://www.datastax.com/dev/blog/cql3-for-cassandra-experts))

"Мы верим, что CQL3 более простой и всеобъемлющий API для Cassandra, нежели Thrift API. Поэтому в новых проектах рекомендуется использовать CQL3. [...] Как CQL3, так и Thrift использует один и тот же уровень хранения данных, поэтому все будущие усовершенствования этого уровня в одинаковой степени коснуться обоих." ([A thrift to CQL3 upgrade guide](http://www.datastax.com/dev/blog/thrift-to-cql3))

"CQL (Cassandra Query Language) - относительно новый SQL-подобный синтаксис запросов к Apache Cassandra. Это удобный интерфейс доступа к Cassandra, являющийся альтернативой Thrift RPC, который, честно говоря, отстой." ([Eric Evans](http://www.acunu.com/2/post/2011/12/cql-benchmarking.html)) [...] CQL предоставляет большую стабильность и простоту в использовании - два аспекта, за которые Cassandra справедливо критиковалась в прошлом. ([CQL benchmarking](http://www.acunu.com/2/post/2011/12/cql-benchmarking.html))Что касается производительности, то, судя по [обзорам](http://www.acunu.com/2/post/2011/12/cql-benchmarking.html), CQL не так сильно отстает от Thrift. Также можно привести достаточно хороший довод относительно производительности CQL:Одно из наиболее частых предположений относительно CQL заключается в том, что возникает необходимость делать разбор строки запроса, следовательно, он (CQL) работает хуже, чем Thrift RPC. Я часто предостерегаю людей от подобных заявлений и указываю на то, что это не строгая игра в показатели производительности. Время разработки является наиболее ценным ресурсом проекта, поэтому вполне достаточно, чтобы производительность была "довольно хороша". [...] Подготовленные выражения ([prepared statements](http://cassandra.apache.org/doc/cql3/CQL.html#preparedStatement)) позволяют делать разбор запроса только один раз и использовать его повторно. ([CQL benchmarking](http://www.acunu.com/2/post/2011/12/cql-benchmarking.html))

# Примеры на CQL

```
-- Создание пространства ключей с именем MultiCare (стратегия репликации - обычная, фактор репликации равен 3)
CREATE KEYSPACE MultiCare WITH replication = { 'class': 'SimpleStrategy', 'replication_factor' : 3 };
 
-- Изменение пространства ключей с именем MultiCare (фактор репликации изменился на 4)
ALTER KEYSPACE MultiCare WITH replication = { 'class': 'SimpleStrategy', 'replication_factor' : 4 };

-- Выбор пространства ключей с именем MultiCare в качестве текущего
USE MultiCare;
 
-- Создание семейства колонок с именем Patient
CREATE TABLE Patient (
   Id uuid PRIMARY KEY,
   FirstName text,
   MiddleName text,
   LastName text,
   BirthTime timestamp,
   IsDeceased boolean,
   DeceasedTime timestamp
)
WITH compaction = { 'class' : 'LeveledCompactionStrategy' };
 
-- Изменение семейства колонок с именем Patient (добавление колонки)
ALTER TABLE Patient ADD Sex int;
 
-- Изменение семейства колонок с именем Patient (изменение настроек)
ALTER TABLE Patient WITH compaction = { 'class' : 'LeveledCompactionStrategy' } AND comment = 'Personal patient data';
 
-- Создание индексов семейства колонок с именем Patient
CREATE INDEX PatientFirstNameIndex ON Patient(FirstName);
CREATE INDEX PatientMiddleNameIndex ON Patient(MiddleName);
CREATE INDEX PatientLastNameIndex ON Patient(LastName);
CREATE INDEX PatientBirthTimeIndex ON Patient(BirthTime);
 
-- Вставка строки в семейство колонок с именем Patient
INSERT INTO Patient(Id, FirstName, MiddleName, LastName) VALUES ('9789F3A8-CDA8-42F2-A066-DC2345F0B1B6', 'Иван', 'Иванович', 'Иванов');
 
-- Вставка строки в семейство колонок с именем Patient (на самом деле - обновление существующей строки)
INSERT INTO Patient(Id, Sex) VALUES ('9789F3A8-CDA8-42F2-A066-DC2345F0B1B6', 1);
 
-- Обновление строки семейства колонок с именем Patient
UPDATE Patient SET IsDeceased = false WHERE Id = '9789F3A8-CDA8-42F2-A066-DC2345F0B1B6'
 
-- Выборка данных из семейства колонок с именем Patient
SELECT * FROM Patient
SELECT * FROM Patient WHERE Id = '9789F3A8-CDA8-42F2-A066-DC2345F0B1B6'
SELECT Id, FirstName, MiddleName, LastName, BirthTime FROM Patient WHERE LastName = 'Иванов'
SELECT * FROM Patient WHERE LastName IN ('Иванов', 'Петров') LIMIT 20
SELECT COUNT(*) FROM Patient
 
-- Удаление колонки из строки семейства колонок с именем  Patient
DELETE IsDeceased FROM Patient WHERE Id = '9789F3A8-CDA8-42F2-A066-DC2345F0B1B6'
 
-- Удаление строки из семейства колонок с именем Patient
DELETE FROM Patient WHERE Id = '9789F3A8-CDA8-42F2-A066-DC2345F0B1B6'
 
-- Удаление индексов семейства колонок с именем Patient
DROP INDEX PatientFirstNameIndex;
DROP INDEX PatientMiddleNameIndex;
DROP INDEX PatientLastNameIndex;
DROP INDEX PatientBirthTimeIndex;


-- Удаление всех данных из семейства колонок с именем Patient
TRUNCATE Patient;


-- Удаление семейства колонок с именем Patient
DROP TABLE Patient;
 
-- Удаление пространства ключей с именем MultiCare
DROP KEYSPACE MultiCare;
```

 

# Несколько советов

* На всех узлах всех дата-центров должно быть установлено одинаковое время и один часовой пояс, так как это влияет на репликацию.
* По умолчанию поиск возможен только по ключам, для возможности поиска по колонкам, нужно создать индекс при создании семейства колонок.
* Существует возможность автоматического добавления узла в кластер, однако нельзя использовать эту возможность в production-режиме. Токены узлов нужно рассчитывать вручную, чтобы нагрузка на узлы была сбалансирована.
* Имеется механизм кэширования, значительно снижающий обращения к жёсткому диску. В настройках размер кэша задаётся в "записях", а не "байтах", поэтому нужно быть осторожным, чтобы не получить "Out Of Memory".
* По мнению авторов управление узлами заключается в двух основных операциях: добавить узел, удалить узел. Если узел "упал" его нужно просто удалить; данные автоматически подтянутся с других узлов.
* Минимально рекомендуемое количество узлов равно 3 (так называемый Replication Factor). Это объясняется тем, что в случае проблем и порчей информации на одном узле всё равно будет большинство узлов с корректной информацией.
* После записи данные попадают в память узла (RAM) и CommitLog (HDD), поэтому лучше использовать узлы с двумя жесткими дисками (HDD), один из которых будет использоваться для CommitLog, другой - для файлов данных.
* Скорость чтения в конечном счете упирается в скорость случайного доступа к диску (HDD), если данные не умещаются целиком в памяти, и в скорость сети, если данные, необходимые для ответа на запрос, находятся на разных серверах.
* Среди методов борьбы с задержками ответа на чтение - увеличение RAM (увеличение кэша), тщательное планирование расположения и схемы данных, запросов к базе.
* Если дата-центры географически удалены, то вместо "Simple Strategy" рекомендуется использовать "Network Topology Strategy" (позволяет описать топологию кластера - в каком дата-центре, в какой стойке находится тот или иной узел).
* Чтобы не устраивать DDoS на пока еще самый быстрый узел, рекомендуется организовать такую логику, при которой клиент последовательно обходит все рабочие узлы по кругу для равномерного распределения нагрузки (если узел долго не отвечает, он считается не рабочим).
* Периодически рекомендуется выполнять процедуру "nodetool compactions", которая выполняет уплотнение таблиц данных. Несмотря на то, что эта процедура выполняется автоматически, ее рекомендуют запускать для профилактики (особенно пред выполнением процедуры repair).
* Периодически рекомендуется выполнять процедуру "nodetool repair", которая выполняет синхронизацию данных между узлами и удаляет данные, которые были помечены, как удаленные. Однако нужно понимать, что это очень ресурсоемкая процедура, требующая хорошей связи между узлами.
* Чтобы уменьшить влияние тяжелой процедуры "nodetool compactions" нужно подобрать оптимальную частоту выполнения этой процедуры (зависит от объема данных), количество параллельных потоков для слияния, а также допустимый дисковый трафик для этой операции.
* Рекомендуется обеспечить запас по месту и по скорости диска (HDD), по объему памяти (RAM), особенно если важно время ответа.
* Рекомендуется использовать одинаковое "железо" для всех узлов (так проще осуществлять балансировку нагрузки).
* При проектировании подходить необходимо не со стороны отношений между сущностями или связями между объектами, а со стороны запросов (лучше постараться сохранить в коночное семейство все, что может понадобиться для этого запроса).

# Установка

Установить Cassandra можно "вручную", как описано в [официальной документации](http://wiki.apache.org/cassandra/GettingStarted), либо воспользоваться [установщиком от DataStax](http://www.datastax.com/documentation/gettingstarted/index.html?pagename=docs&version=quick_start&file=quickstart).

# Дополнительная информация

[Cassandra](http://cassandra.apache.org/) - официальный сайт

[Cassandra API](http://wiki.apache.org/cassandra/API) - официальная документация

[Документация на datastax.com](http://www.datastax.com/docs) - документация сообщества DataStax

[Planet Cassandra](http://planetcassandra.org/) - DataStax Community Edition

[WTF is a SuperColumn? Введение в модель данных Cassandra](http://habrahabr.ru/post/100075/) - приводится подробнейшее описание модели данных

[Cassandra глазами Operations](http://habrahabr.ru/company/lifestreet/blog/146115/) - набор советов по администрированию и оптимальной настройке

[Опыт спасения кластера Cassandra](http://habrahabr.ru/post/114160/) - набор советов по замене узлов в кластере

[Как устроена Apache Cassandra](http://habrahabr.ru/post/155115/) - подробно рассматриваются принципы работы

[Cassandra как распределенная NoSQL база данных](http://jeeconf.com/archive/jeeconf-2011/materials/cassandra/) - видео-доклад о принципах работы

[CQL benchmarking](http://www.acunu.com/2/post/2011/12/cql-benchmarking.html) - сравнение производительности CQL и Thrift

[CQL3 for Cassandra experts](http://www.datastax.com/dev/blog/cql3-for-cassandra-experts) - рассматриваются возможности CQL3 и приводится практический пример создания программной модели

[Cassandra Jump Start For The Windows Developer](http://coderjournal.com/2010/03/cassandra-jump-start-for-the-windows-developer/) - описание процесса установки (немного устаревшее)

 

 

